{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/users/fs2/hmehri/pythonproject/Thesis/synthetic')\n",
    "\n",
    "from lib.field_info import FieldInfo_type2\n",
    "from lib.tensor_encoder import TensorEncoder\n",
    "from lib.prepare_data import preprocess_data_czech\n",
    "from lib.modules import Encoder_Decoder_lstm, Encoder_Decoder_lstm_Inference\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainlstm import Train\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unittest\n",
    "import calendar\n",
    "import datetime\n",
    "pd.set_option('display.max_rows', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding 2000 of 10995 seqs\n",
      "Finished encoding 4000 of 10995 seqs\n",
      "Finished encoding 6000 of 10995 seqs\n",
      "Finished encoding 8000 of 10995 seqs\n",
      "Finished encoding 10000 of 10995 seqs\n",
      "Took 25.68 secs\n",
      "Epoch 1 Batch0 Loss 14.3662\n",
      "Epoch 1 Batch50 Loss 6.9773\n",
      "Epoch 1 Batch100 Loss 6.5392\n",
      "Epoch 1 Loss 6.3725\n",
      "** on validation data loss is 5.8485\n",
      "Time taken for 1 epoch: 5.88 secs\n",
      "\n",
      "Epoch 2 Batch0 Loss 5.8371\n",
      "Epoch 2 Batch50 Loss 5.7878\n",
      "Epoch 2 Batch100 Loss 5.7411\n",
      "Epoch 2 Loss 5.7061\n",
      "** on validation data loss is 5.6033\n",
      "Time taken for 1 epoch: 5.76 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/users/fs2/hmehri/pythonproject/Thesis/synthetic')\n",
    "\n",
    "from lib.prepare_data import preprocess_data_czech\n",
    "from lib.field_info import FieldInfo, FIELD_INFO_TCODE, FieldInfo_type2\n",
    "from lib.tensor_encoder import TensorEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lib.modules import Encoder_Decoder_lstm\n",
    "from trainlstm import Train\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "    return config\n",
    "\n",
    "def log_parameters(filename, parameters):\n",
    "    log_entry = {'filename': filename, 'parameters': parameters}\n",
    "    with open('parameter_log.json', 'a') as file:\n",
    "        json.dump(log_entry, file)\n",
    "        file.write('\\n')  # New line for each entry\n",
    "\n",
    "\n",
    "def make_batches(ds, buffer_size, batch_size):\n",
    "    return ds.cache().shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def create_tensor_dataset(encoder,bs, split=True):\n",
    "    \"\"\"bs is Batch Size\n",
    "       if split=True, the input data is split into train and validation, otherwise the whole data is used for training \"\"\"\n",
    "    n_seqs, _, _ = encoder.inp_tensor.shape\n",
    "\n",
    "    x_tr, x_cv, inds_tr, inds_cv, targ_tr, targ_cv = train_test_split(encoder.inp_tensor, np.arange(n_seqs), encoder.tar_tensor, test_size=0.2)\n",
    "\n",
    "    # Create TensorFlow dataset\n",
    "    ds_all = tf.data.Dataset.from_tensor_slices((encoder.inp_tensor.astype(np.float32), encoder.tar_tensor.astype(np.float32)))\n",
    "    ds_tr = tf.data.Dataset.from_tensor_slices((x_tr.astype(np.float32), targ_tr.astype(np.float32)))\n",
    "    ds_cv = tf.data.Dataset.from_tensor_slices((x_cv.astype(np.float32), targ_cv.astype(np.float32)))\n",
    "\n",
    "    BUFFER_SIZE = ds_all.cardinality().numpy()\n",
    "\n",
    "    all_batches =   make_batches(ds_all, BUFFER_SIZE, bs)\n",
    "    train_batches = make_batches(ds_tr, BUFFER_SIZE, bs)\n",
    "    val_batches =  make_batches(ds_cv, BUFFER_SIZE, bs)\n",
    "\n",
    "    if split:\n",
    "        return train_batches, val_batches\n",
    "    else:\n",
    "        return all_batches\n",
    "\n",
    "\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    raw_data = pd.read_csv('../DATA/tr_by_acct_w_age.csv')\n",
    "    data, LOG_AMOUNT_SCALE, TD_SCALE,ATTR_SCALE, START_DATE, _ = preprocess_data_czech(raw_data)\n",
    "    data2 = data[['account_id','age','age_sc', 'tcode', 'tcode_num', 'datetime', 'month', 'dow', 'day','td', 'dtme', 'log_amount','log_amount_sc','td_sc',\n",
    "                                'type','operation', 'k_symbol', 'type_num', 'operation_num', 'k_symbol_num']]\n",
    "    #data2 =  data[['account_id', 'tcode_num', 'age_sc', 'tcode', 'age']]\n",
    "    df= data2.copy()\n",
    "\n",
    "    confighyper = load_config('config_hyper.json')\n",
    "    max_seq_len = confighyper['max_seq_len']\n",
    "    min_seq_len = confighyper['min_seq_len']\n",
    "    batch_size = confighyper['batch_size']\n",
    "    epochs = confighyper['epochs'] \n",
    "    early_stop = confighyper['early_stop'] \n",
    "    len_generated_seq = confighyper['len_generated_seq'] \n",
    "    num_generated_seq = confighyper['num_generated_seq'] \n",
    "    synth_data_filename = confighyper[\"synth_data_filename\"]\n",
    "    strategy = confighyper['strategy']\n",
    "\n",
    "    info = FieldInfo(strategy)\n",
    "    #info = FIELD_INFO_TCODE()\n",
    "    #info = FieldInfo_type2()\n",
    "\n",
    "    \n",
    "    encoder = TensorEncoder(df, info, max_seq_len, min_seq_len)\n",
    "    encoder.encode_with_overlap(slide_step=80)\n",
    "\n",
    "    n_seqs, seq_len, n_feat_inp = encoder.inp_tensor.shape\n",
    "    raw_features = encoder.tar_tensor.shape[-1]    #7\n",
    "\n",
    "    train_batches, val_batches = create_tensor_dataset(encoder, batch_size, split=True)\n",
    "\n",
    "\n",
    "\n",
    "    config = {}\n",
    "    config[\"ORDER\"] = info.DATA_KEY_ORDER\n",
    "    config[\"FIELD_STARTS_IN\"] = info.FIELD_STARTS_IN\n",
    "    config[\"FIELD_DIMS_IN\"] = info.FIELD_DIMS_IN\n",
    "    config[\"FIELD_STARTS_NET\"] = info.FIELD_STARTS_NET\n",
    "    config[\"FIELD_DIMS_NET\"] = info.FIELD_DIMS_NET\n",
    "    config[\"ACTIVATIONS\"] = info.ACTIVATIONS\n",
    "\n",
    "    lstm = Encoder_Decoder_lstm(config, n_feat_inp, conditional=True)\n",
    "    train = Train(lstm)\n",
    "    train.train(train_batches, val_batches, epochs=epochs, early_stop=early_stop)\n",
    "    attributes = encoder.attributes\n",
    "\n",
    "    # synth = train.generate_synthetic_data(len_generated_seq, num_generated_seq, df, attributes, n_feat_inp)\n",
    "    # #synth = train.generate_synthetic_tcode(len_generated_seq,num_generated_seq, df, attributes, n_feat_inp)\n",
    "    # #synth = train.generate_synthetic_data_type2(len_generated_seq,num_generated_seq, df, attributes, n_feat_inp)\n",
    "\n",
    "    # synth.to_csv(synth_data_filename, index=False)\n",
    "    \n",
    "    # log_parameters(synth_data_filename, confighyper)\n",
    "    # print('finish')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder__decoder_lstm_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                multiple                  79360     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                multiple                  131584    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               multiple                  131584    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               multiple                  131584    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             multiple                  4619      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  1015      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  4681      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             multiple                  308       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             multiple                  1764      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  2064      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             multiple                  306       \n",
      "=================================================================\n",
      "Total params: 488,869\n",
      "Trainable params: 488,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.334760</td>\n",
       "      <td>5.957420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.758039</td>\n",
       "      <td>5.629686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.579495</td>\n",
       "      <td>5.510149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.447209</td>\n",
       "      <td>5.385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.317694</td>\n",
       "      <td>5.249732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4.246257</td>\n",
       "      <td>4.388506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.280646</td>\n",
       "      <td>4.337390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.223671</td>\n",
       "      <td>4.380812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.217332</td>\n",
       "      <td>4.316156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4.236193</td>\n",
       "      <td>4.348280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   6.334760  5.957420\n",
       "1   5.758039  5.629686\n",
       "2   5.579495  5.510149\n",
       "3   5.447209  5.385936\n",
       "4   5.317694  5.249732\n",
       "..       ...       ...\n",
       "61  4.246257  4.388506\n",
       "62  4.280646  4.337390\n",
       "63  4.223671  4.380812\n",
       "64  4.217332  4.316156\n",
       "65  4.236193  4.348280\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loss = pd.read_csv('loss_lstm_dp1.csv')\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tcode_num': 16, 'td_sc': 1, 'log_amount_sc': 1},\n",
       " {'tcode_num': 16, 'td_sc': 2, 'log_amount_sc': 2},\n",
       " {'tcode_num': 1, 'td_sc': 1, 'log_amount_sc': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = FieldInfo_type2()\n",
    "info.FIELD_DIMS_IN, info.FIELD_DIMS_NET, info.FIELD_DIMS_TAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../DATA/tr_by_acct_w_age.csv')\n",
    "data, LOG_AMOUNT_SCALE, TD_SCALE,ATTR_SCALE, START_DATE, TCODE_TO_NUM, NUM_TO_TCODE = preprocess_data_czech(raw_data)\n",
    "data2 = data[['account_id','age','age_sc', 'tcode', 'tcode_num', 'datetime', 'month', 'dow', 'day','td', 'dtme', 'log_amount','log_amount_sc','td_sc']]\n",
    "df= data2.copy()\n",
    "\n",
    "max_seq_len = 80\n",
    "min_seq_len = 20\n",
    "\n",
    "encoder = TensorEncoder(df, info, max_seq_len, min_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished encoding 2000 of 14354 seqs\n",
      "Finished encoding 4000 of 14354 seqs\n",
      "Finished encoding 6000 of 14354 seqs\n",
      "Finished encoding 8000 of 14354 seqs\n",
      "Finished encoding 10000 of 14354 seqs\n",
      "Finished encoding 12000 of 14354 seqs\n",
      "Finished encoding 14000 of 14354 seqs\n",
      "Took 38.53 secs\n"
     ]
    }
   ],
   "source": [
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14354, 81, 26), (14354, 80, 11))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inp_tensor.shape, encoder.tar_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds, buffer_size, batch_size):\n",
    "    return ds.cache().shuffle(buffer_size).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "n_seqs, n_steps, n_feat_inp = encoder.inp_tensor.shape\n",
    "x_tr, x_cv, inds_tr, inds_cv, targ_tr, targ_cv = train_test_split(encoder.inp_tensor, np.arange(n_seqs), encoder.tar_tensor, test_size=0.2)\n",
    "\n",
    "# Create TensorFlow dataset\n",
    "ds_all = tf.data.Dataset.from_tensor_slices((encoder.inp_tensor.astype(np.float32), encoder.tar_tensor.astype(np.float32)))\n",
    "ds_tr = tf.data.Dataset.from_tensor_slices((x_tr.astype(np.float32), targ_tr.astype(np.float32)))\n",
    "ds_cv = tf.data.Dataset.from_tensor_slices((x_cv.astype(np.float32), targ_cv.astype(np.float32)))\n",
    "\n",
    "BUFFER_SIZE = ds_all.cardinality().numpy()\n",
    "bs = 64  # batch size\n",
    "\n",
    "\n",
    "train_batches = make_batches(ds_tr, BUFFER_SIZE, bs)\n",
    "val_batches =  make_batches(ds_cv, BUFFER_SIZE, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for (batch_no, (inp, tar)) in enumerate(train_batches):\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"ORDER\"] = info.DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = info.FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = info.FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = info.FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = info.FIELD_DIMS_NET\n",
    "config[\"ACTIVATIONS\"] = info.ACTIVATIONS\n",
    "inp_feat = sum(info.FIELD_DIMS_IN.values())\n",
    "lstm = Encoder_Decoder_lstm(config, inp_feat, conditional=True)\n",
    "train = Train(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lstm(inp)\n",
    "real = tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "real = tar\n",
    "INP_ENCODING = info.INP_ENCODINGS\n",
    "NET_ENCODING = info.NET_ENCODINGS\n",
    "FIELD_STARTS_TAR = info.FIELD_STARTS_TAR\n",
    "FIELD_DIMS_TAR = info.FIELD_DIMS_TAR\n",
    "LOSS_TYPES = info.LOSS_TYPES\n",
    "FIELD_STARTS_IN = info.FIELD_STARTS_IN\n",
    "FIELD_DIMS_IN = info.FIELD_DIMS_IN\n",
    "FIELD_DIMS_NET = info.FIELD_DIMS_NET\n",
    "loss_scce_logit = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "loss_mse = tf.keras.losses.MeanSquaredError(reduction='none')\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return  -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n",
    "\n",
    "LOSS_WEIGHTS = {\n",
    " 'td_sc':1.,\n",
    " 'month': 0.015,\n",
    " 'day': 0.025,\n",
    " 'dtme': 0.025,\n",
    " 'dow': 0.01,\n",
    " 'tcode_num': 1.,\n",
    " 'log_amount_sc': 2.}\n",
    "\n",
    "loss_parts = []\n",
    "loss_parts_weighted = []\n",
    "mask = tf.math.logical_not(tf.math.equal(tf.reduce_sum(real, axis=2), 0))\n",
    "for k, k_pred in preds.items():\n",
    "    st = FIELD_STARTS_TAR[k]\n",
    "    end = st + FIELD_DIMS_TAR[k]\n",
    "    loss_type = LOSS_TYPES[k]\n",
    "    if loss_type == \"scce\":\n",
    "        loss_ = loss_scce_logit(real[:, :, st:end], k_pred)\n",
    "    elif loss_type == \"pdf\":\n",
    "        loss_ = -log_normal_pdf(real[:, :, st:end], k_pred[:,:,0:1], k_pred[:,:,1:2])[:,:,0]\n",
    "    elif loss_type == 'mse':\n",
    "        loss_ = loss_mse(real[:, :, st:end], k_pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    loss_ = tf.reduce_sum(loss_)/tf.reduce_sum(mask) \n",
    "\n",
    "    loss_parts.append(loss_)\n",
    "    loss_parts_weighted.append(loss_ * LOSS_WEIGHTS[k])\n",
    "#return tf.reduce_sum(loss_parts_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 09:54:06.678997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24cf11e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-30 09:54:06.679022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "2023-12-30 09:54:06.679026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5\n",
      "2023-12-30 09:54:06.683211: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-30 09:54:06.780018: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f7cf4159310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f7cf4159310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1 Batch0 Loss 21.7639\n",
      "Epoch 1 Batch50 Loss 6.3287\n",
      "Epoch 1 Batch100 Loss 5.6140\n",
      "Epoch 1 Batch150 Loss 5.2996\n",
      "Epoch 1 Loss 5.1793\n",
      "** on validation data loss is 4.4675\n",
      "Time taken for 1 epoch: 18.14 secs\n",
      "\n",
      "Epoch 2 Batch0 Loss 4.4306\n",
      "Epoch 2 Batch50 Loss 4.4150\n",
      "Epoch 2 Batch100 Loss 4.3478\n",
      "Epoch 2 Batch150 Loss 4.3036\n",
      "Epoch 2 Loss 4.2862\n",
      "** on validation data loss is 4.1555\n",
      "Time taken for 1 epoch: 15.29 secs\n",
      "\n",
      "Epoch 3 Batch0 Loss 4.2472\n",
      "Epoch 3 Batch50 Loss 4.0839\n",
      "Epoch 3 Batch100 Loss 4.0508\n",
      "Epoch 3 Batch150 Loss 4.0077\n",
      "Epoch 3 Loss 3.9831\n",
      "** on validation data loss is 3.8243\n",
      "Time taken for 1 epoch: 15.84 secs\n",
      "\n",
      "Epoch 4 Batch0 Loss 3.8001\n",
      "Epoch 4 Batch50 Loss 3.8267\n",
      "Epoch 4 Batch100 Loss 3.8174\n",
      "Epoch 4 Batch150 Loss 3.7922\n",
      "Epoch 4 Loss 3.7887\n",
      "** on validation data loss is 3.7135\n",
      "Time taken for 1 epoch: 15.65 secs\n",
      "\n",
      "Epoch 5 Batch0 Loss 3.7687\n",
      "Epoch 5 Batch50 Loss 3.7265\n",
      "Epoch 5 Batch100 Loss 3.6922\n",
      "Epoch 5 Batch150 Loss 3.6631\n",
      "Epoch 5 Loss 3.6584\n",
      "** on validation data loss is 3.5993\n",
      "Time taken for 1 epoch: 15.71 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.train(train_batches, val_batches, epochs=5, early_stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14354,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = encoder.attributes\n",
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate synthetic data\n",
    "n_seqs_to_generate = 3\n",
    "attributes = encoder.attributes\n",
    "max_length = 25\n",
    "\n",
    "MAX_YEARS_SPAN = 15\n",
    "get_dtme = lambda d: calendar.monthrange(d.year, d.month)[1] - d.day\n",
    "\n",
    "START_DATE = df[\"datetime\"].min()\n",
    "ATTR_SCALE = df[\"age\"].std()\n",
    "LOG_AMOUNT_SCALE = df[\"log_amount\"].std()\n",
    "TD_SCALE = df[\"td\"].std()\n",
    "NUM_TO_TCODE = dict([(i, tc) for i, tc in enumerate(df['tcode'].unique())])\n",
    "\n",
    "END_DATE = START_DATE.replace(year = START_DATE.year+ MAX_YEARS_SPAN)\n",
    "\n",
    "ALL_DATES = [START_DATE + datetime.timedelta(i) for i in range((END_DATE - START_DATE).days)]\n",
    "AD = np.array([(d.month % 12, d.day % 31, d.weekday() % 7, i, d.year, get_dtme(d)) for i, d in enumerate(ALL_DATES)])\n",
    "start_date_opts = df.groupby(\"account_id\")[\"datetime\"].min().dt.date.to_list()   #len = 4500\n",
    "start_dates = np.random.choice(start_date_opts, size=n_seqs_to_generate) # sample start dates from real data\n",
    "\n",
    "seq_ages = np.random.choice(attributes, size=n_seqs_to_generate) # sample ages from real data\n",
    "\n",
    "#generate sequences\n",
    "start_inds = np.array([(d - START_DATE.date()).days for d in start_dates])    #array of shape (n_seqs_to_generate,)\n",
    "#print(start_inds)\n",
    "inp = np.repeat(np.array(seq_ages)[:, None, None], repeats=n_feat_inp, axis=2) / ATTR_SCALE   #(n_seqs_to_generate, 1, n_feat_inp) \n",
    "raw_date_info_list = []\n",
    "\n",
    "conditional = train.lstm.conditional\n",
    "inference_model = Encoder_Decoder_lstm_Inference(train.lstm.config, train.lstm.inp_feat, conditional)\n",
    "dummy_input = tf.random.normal([n_seqs_to_generate, max_length, n_feat_inp])\n",
    "# Build the model by running dummy data through it\n",
    "inference_model(dummy_input)\n",
    "inference_model.load_weights('lstm_model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_encode_time_value(val, max_val):\n",
    "    \"\"\" encoding date features in the clockwise dimension \"\"\"\n",
    "    x = np.sin(2 * np.pi / max_val * val)\n",
    "    y = np.cos(2 * np.pi / max_val * val)\n",
    "    return np.stack([x, y], axis=1)\n",
    "\n",
    "def clock_to_probs(pt, pts):\n",
    "    EPS_CLOCKP = 0.01\n",
    "    pt_expanded = tf.expand_dims(pt, 2)                     # Shape: (n_seq, seq_len, 1, 2)\n",
    "    pts_expanded = tf.reshape(pts, [1, 1, pts.shape[0], 2]) # Shape: (1, 1, net_dim, 2)\n",
    "\n",
    "    ds = tf.constant(pts_expanded) - pt_expanded\n",
    "    print(ds.shape)\n",
    "    sq_ds = np.sum(tf.square(ds+EPS_CLOCKP), axis= -1)\n",
    "    print(sq_ds.shape)\n",
    "    raw_ps = 1/ sq_ds   \n",
    "    return raw_ps / np.sum(raw_ps)\n",
    "\n",
    "def reencode_net_prediction(net_name, predictions):\n",
    "    \"\"\"net_name is in ['tcode_num', 'dow', 'month', 'day', 'dtme', 'td_sc', 'log_amount_sc']\n",
    "       predictions for ['tcode_num', 'dow', 'month', 'day', 'dtme'] are probabilities of dimensions [16, 7, 12, 31, 31]\n",
    "\n",
    "       function:  transform predictions to the correct form to be used for conditional generating: \n",
    "                  convert 'tcode' to one-hot encoded vector, \n",
    "                  convert date features to clock dimension\n",
    "                  extract the predicted mean of 'td' and 'amount' as predicted values \n",
    "                \n",
    "    \"\"\"\n",
    "    date_info = {'month':12, 'day':31, 'dtme':31, 'dow':7}\n",
    "    CLOCKS = {}\n",
    "    for k, val in date_info.items():\n",
    "        CLOCKS[k] = tf.constant(bulk_encode_time_value(np.arange(val), val), dtype=tf.float32)\n",
    "        \n",
    "    batch_size = predictions.shape[0]\n",
    "    print('prediction shape', predictions.shape)\n",
    "    if \"_num\" in net_name:\n",
    "        dim = FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)    #predictions: (n_seq_to_generate, seq_len, dim=16)\n",
    "        choosen =  np.reshape([np.random.choice(choices, p=p) for p in ps], newshape=(batch_size, -1))\n",
    "\n",
    "        return tf.one_hot(choosen, depth=dim)      #(n_seq_to_generate, seq_len, dim=16)\n",
    "    \n",
    "    elif net_name in date_info.keys() and INP_ENCODING[net_name] == 'cl' and 'oh' in NET_ENCODING[net_name] :\n",
    "\n",
    "        dim = FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)\n",
    "        choosen =  np.array([np.random.choice(choices, p=p) for p in ps])\n",
    "        x = bulk_encode_time_value(choosen, max_val=dim)\n",
    "        \n",
    "        return np.reshape(x, newshape=(batch_size, -1, 2))\n",
    "    \n",
    "    elif net_name in date_info.keys() and 'oh' in INP_ENCODING[net_name] and 'oh' in NET_ENCODING[net_name]:\n",
    "        dim = FIELD_DIMS_NET[net_name]\n",
    "        assert predictions.shape[-1] == dim\n",
    "        choices = np.arange(dim)\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)    #predictions: (n_seq_to_generate, seq_len, dim=dim)\n",
    "        choosen =  np.reshape([np.random.choice(choices, p=p) for p in ps], newshape=(batch_size, -1))\n",
    "        \n",
    "        return tf.one_hot(choosen, depth=dim) \n",
    "    elif net_name in date_info.keys() and 'cl' in INP_ENCODING[net_name] and 'cl' in NET_ENCODING[net_name]:\n",
    "        dim = date_info[net_name]\n",
    "        assert predictions.shape[-1] == FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "        print(CLOCKS[net_name])\n",
    "        print(predictions.shape)\n",
    "        preds = clock_to_probs(predictions, CLOCKS[net_name])\n",
    "        print(preds.shape)\n",
    "        ps = tf.nn.softmax(preds, axis=2).numpy().reshape(-1, dim)    #predictions: (n_seq_to_generate, seq_len, dim=dim)\n",
    "        choosen =  np.reshape([np.random.choice(choices, p=p) for p in ps], newshape=(batch_size, -1))\n",
    "        x = bulk_encode_time_value(choosen, max_val=dim)\n",
    "        \n",
    "        return np.reshape(x, newshape=(batch_size, -1, 2))\n",
    "    elif net_name in ['td_sc', \"log_amount_sc\"]:\n",
    "        return predictions[:, :, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction shape (3, 1, 16)\n",
      "prediction shape (3, 1, 2)\n",
      "tf.Tensor(\n",
      "[[ 0.          1.        ]\n",
      " [ 0.7818315   0.6234898 ]\n",
      " [ 0.9749279  -0.22252093]\n",
      " [ 0.43388373 -0.90096885]\n",
      " [-0.43388373 -0.90096885]\n",
      " [-0.9749279  -0.22252093]\n",
      " [-0.7818315   0.6234898 ]], shape=(7, 2), dtype=float32)\n",
      "(3, 1, 2)\n",
      "(3, 1, 7, 2)\n",
      "(3, 1, 7)\n",
      "(3, 1, 7)\n",
      "prediction shape (3, 1, 2)\n",
      "tf.Tensor(\n",
      "[[ 0.0000000e+00  1.0000000e+00]\n",
      " [ 5.0000000e-01  8.6602539e-01]\n",
      " [ 8.6602539e-01  5.0000000e-01]\n",
      " [ 1.0000000e+00  6.1232343e-17]\n",
      " [ 8.6602539e-01 -5.0000000e-01]\n",
      " [ 5.0000000e-01 -8.6602539e-01]\n",
      " [ 1.2246469e-16 -1.0000000e+00]\n",
      " [-5.0000000e-01 -8.6602539e-01]\n",
      " [-8.6602539e-01 -5.0000000e-01]\n",
      " [-1.0000000e+00 -1.8369701e-16]\n",
      " [-8.6602539e-01  5.0000000e-01]\n",
      " [-5.0000000e-01  8.6602539e-01]], shape=(12, 2), dtype=float32)\n",
      "(3, 1, 2)\n",
      "(3, 1, 12, 2)\n",
      "(3, 1, 12)\n",
      "(3, 1, 12)\n",
      "prediction shape (3, 1, 2)\n",
      "tf.Tensor(\n",
      "[[ 0.          1.        ]\n",
      " [ 0.20129852  0.9795299 ]\n",
      " [ 0.39435586  0.9189578 ]\n",
      " [ 0.5712682   0.82076347]\n",
      " [ 0.7247928   0.68896693]\n",
      " [ 0.84864426  0.528964  ]\n",
      " [ 0.9377521   0.34730524]\n",
      " [ 0.98846835  0.15142778]\n",
      " [ 0.99871653 -0.05064917]\n",
      " [ 0.9680771  -0.25065252]\n",
      " [ 0.89780456 -0.44039416]\n",
      " [ 0.7907757  -0.61210597]\n",
      " [ 0.6513725  -0.7587581 ]\n",
      " [ 0.48530197 -0.8743466 ]\n",
      " [ 0.29936314 -0.95413923]\n",
      " [ 0.10116832 -0.99486935]\n",
      " [-0.10116832 -0.99486935]\n",
      " [-0.29936314 -0.95413923]\n",
      " [-0.48530197 -0.8743466 ]\n",
      " [-0.6513725  -0.7587581 ]\n",
      " [-0.7907757  -0.61210597]\n",
      " [-0.89780456 -0.44039416]\n",
      " [-0.9680771  -0.25065252]\n",
      " [-0.99871653 -0.05064917]\n",
      " [-0.98846835  0.15142778]\n",
      " [-0.9377521   0.34730524]\n",
      " [-0.84864426  0.528964  ]\n",
      " [-0.7247928   0.68896693]\n",
      " [-0.5712682   0.82076347]\n",
      " [-0.39435586  0.9189578 ]\n",
      " [-0.20129852  0.9795299 ]], shape=(31, 2), dtype=float32)\n",
      "(3, 1, 2)\n",
      "(3, 1, 31, 2)\n",
      "(3, 1, 31)\n",
      "(3, 1, 31)\n",
      "prediction shape (3, 1, 2)\n",
      "tf.Tensor(\n",
      "[[ 0.          1.        ]\n",
      " [ 0.20129852  0.9795299 ]\n",
      " [ 0.39435586  0.9189578 ]\n",
      " [ 0.5712682   0.82076347]\n",
      " [ 0.7247928   0.68896693]\n",
      " [ 0.84864426  0.528964  ]\n",
      " [ 0.9377521   0.34730524]\n",
      " [ 0.98846835  0.15142778]\n",
      " [ 0.99871653 -0.05064917]\n",
      " [ 0.9680771  -0.25065252]\n",
      " [ 0.89780456 -0.44039416]\n",
      " [ 0.7907757  -0.61210597]\n",
      " [ 0.6513725  -0.7587581 ]\n",
      " [ 0.48530197 -0.8743466 ]\n",
      " [ 0.29936314 -0.95413923]\n",
      " [ 0.10116832 -0.99486935]\n",
      " [-0.10116832 -0.99486935]\n",
      " [-0.29936314 -0.95413923]\n",
      " [-0.48530197 -0.8743466 ]\n",
      " [-0.6513725  -0.7587581 ]\n",
      " [-0.7907757  -0.61210597]\n",
      " [-0.89780456 -0.44039416]\n",
      " [-0.9680771  -0.25065252]\n",
      " [-0.99871653 -0.05064917]\n",
      " [-0.98846835  0.15142778]\n",
      " [-0.9377521   0.34730524]\n",
      " [-0.84864426  0.528964  ]\n",
      " [-0.7247928   0.68896693]\n",
      " [-0.5712682   0.82076347]\n",
      " [-0.39435586  0.9189578 ]\n",
      " [-0.20129852  0.9795299 ]], shape=(31, 2), dtype=float32)\n",
      "(3, 1, 2)\n",
      "(3, 1, 31, 2)\n",
      "(3, 1, 31)\n",
      "(3, 1, 31)\n",
      "prediction shape (3, 1, 2)\n",
      "prediction shape (3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "lstm = inference_model\n",
    "final_output = lstm(inp, return_decoder_lstm2_output=True)\n",
    "\n",
    "### Predict each field  ###\n",
    "\n",
    "#raw_preds is the outputs of the last dense layer of deep model. \n",
    "raw_preds = {}\n",
    "#preds is the reencoded raw_preds, 'tcode' converts to one-hot encoded, 'date-features' are converted to clock-wise\n",
    "#and for 'amount' and 'td' the predicted mean is extracted. it is used for conditional generating. \n",
    "preds = {}\n",
    "#encoded_preds_d is similar to preds for 'tcode', 'td', and 'amount', but for date features , the predicted date is computed \n",
    "#based on a formula \n",
    "encoded_preds_d = {}\n",
    "\n",
    "if lstm.conditional:\n",
    "    for net_name in lstm.ORDER:  \n",
    "\n",
    "        raw_preds[net_name] = lstm.dense_layers[net_name](final_output)\n",
    "        en_pred = reencode_net_prediction(net_name, raw_preds[net_name]) \n",
    "        preds[net_name] = en_pred\n",
    "            \n",
    "        encoded_preds_d[net_name] = en_pred[:,-1,:] \n",
    "        #encoded_preds.append(pred[:,-1,:])\n",
    "        final_output = tf.concat([final_output, en_pred], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call to generate \n",
    "lstm = inference_model\n",
    "final_output = lstm(inp, return_decoder_lstm2_output=True)\n",
    "\n",
    "### Predict each field  ###\n",
    "\n",
    "#raw_preds is the outputs of the last dense layer of deep model. \n",
    "raw_preds = {}\n",
    "#preds is the reencoded raw_preds, 'tcode' converts to one-hot encoded, 'date-features' are converted to clock-wise\n",
    "#and for 'amount' and 'td' the predicted mean is extracted. it is used for conditional generating. \n",
    "preds = {}\n",
    "#encoded_preds_d is similar to preds for 'tcode', 'td', and 'amount', but for date features , the predicted date is computed \n",
    "#based on a formula \n",
    "encoded_preds_d = {}\n",
    "\n",
    "if lstm.conditional:\n",
    "    for net_name in lstm.ORDER:  \n",
    "\n",
    "        raw_preds[net_name] = lstm.dense_layers[net_name](final_output)\n",
    "        en_pred = reencode_net_prediction(net_name, raw_preds[net_name]) \n",
    "        preds[net_name] = en_pred\n",
    "            \n",
    "        encoded_preds_d[net_name] = en_pred[:,-1,:] \n",
    "        #encoded_preds.append(pred[:,-1,:])\n",
    "        final_output = tf.concat([final_output, en_pred], axis=2)\n",
    "\n",
    "    \n",
    "else:\n",
    "    final_output = lstm.dense_layer(final_output)\n",
    "    st = 0\n",
    "    for net_name, dim in lstm.FIELD_DIMS_NET.items():\n",
    "        acti = lstm.ACTIVATIONS.get(net_name, None)\n",
    "        ed = st + dim\n",
    "        if acti is None:\n",
    "            raw_preds[net_name] = final_output[:,:,st:ed]\n",
    "        elif acti == 'relu':\n",
    "            raw_preds[net_name] = tf.keras.activations.relu(final_output[:, :, st:ed])\n",
    "        st = ed\n",
    "\n",
    "        en_pred = reencode_net_prediction(net_name, raw_preds[net_name]) \n",
    "        preds[net_name] = en_pred\n",
    "\n",
    "        encoded_preds_d[net_name] = en_pred[:,-1,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 09:59:32.560111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47372 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2023-12-29 09:59:32.560603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47372 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:af:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bulk_encode_time_value(val, max_val):\n",
    "    \"\"\" encoding date features in the clockwise dimension \"\"\"\n",
    "    x = np.sin(2 * np.pi / max_val * val)\n",
    "    y = np.cos(2 * np.pi / max_val * val)\n",
    "    return np.stack([x, y], axis=1)\n",
    "date_info = {'month':12, 'day':31, 'dtme':31, 'dow':7}\n",
    "CLOCKS = {}\n",
    "for k, val in date_info.items():\n",
    "    CLOCKS[k] = tf.constant(bulk_encode_time_value(np.arange(val), val), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock_to_probs(pt, pts):\n",
    "    EPS_CLOCKP = 0.01\n",
    "    ds = tf.constant(pts) - pt\n",
    "    sq_ds = np.sum(tf.square(ds+EPS_CLOCKP), axis=1)\n",
    "    raw_ps = 1/ sq_ds   \n",
    "    return raw_ps / np.sum(raw_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = CLOCKS['month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 23:04:08.029628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-27 23:04:08.304819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23cf2990 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-27 23:04:08.304843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "2023-12-27 23:04:08.304846: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Quadro RTX 8000, Compute Capability 7.5\n",
      "2023-12-27 23:04:08.329707: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-27 23:04:08.544273: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f3dd2a0a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f3dd2a0a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1 Batch0 Loss 14.9649\n",
      "Epoch 1 Batch50 Loss 7.2448\n",
      "Epoch 1 Batch100 Loss 6.8731\n",
      "Epoch 1 Batch150 Loss 6.7448\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'encoder__decoder_lstm' (type Encoder_Decoder_lstm).\n\nInput 0 of layer \"lstm\" is incompatible with the layer: expected shape=(64, None, 26), found shape=(27, 80, 26)\n\nCall arguments received by layer 'encoder__decoder_lstm' (type Encoder_Decoder_lstm):\n  • inp=tf.Tensor(shape=(27, 81, 26), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pythonproject/Thesis/synthetic/lstmModel/trainlstm.py:269\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, train_batches, val_batches, epochs, early_stop)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_loss\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch_no, (inp, tar)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_batches):\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m    270\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(inp)\n\u001b[1;32m    271\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_function(tar, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/pythonproject/Thesis/synthetic/lib/modules.py:367\u001b[0m, in \u001b[0;36mEncoder_Decoder_lstm.call\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    364\u001b[0m inp_out \u001b[38;5;241m=\u001b[39m inp[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m output1, state_h1, state_c1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_lstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m output2, state_h2, state_c2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_lstm2(output1)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Decoder\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'encoder__decoder_lstm' (type Encoder_Decoder_lstm).\n\nInput 0 of layer \"lstm\" is incompatible with the layer: expected shape=(64, None, 26), found shape=(27, 80, 26)\n\nCall arguments received by layer 'encoder__decoder_lstm' (type Encoder_Decoder_lstm):\n  • inp=tf.Tensor(shape=(27, 81, 26), dtype=float32)"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "early_stop = 3\n",
    "train.train(train_batches, val_batches, epochs, early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlstm\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm' is not defined"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 25\n",
    "n_seqs_to_generate = 3\n",
    "attributes = encoder.attributes\n",
    "n_seqs, seq_len, n_feat_inp = encoder.inp_tensor.shape\n",
    "train.generate_synthetic_data(max_length, n_seqs_to_generate, df, attributes, n_feat_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/users/fs2/hmehri/pythonproject/Thesis/synthetic')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.prepare_data import preprocess_data_czech\n",
    "from lib.eval import comapre_unidist_cont, compute_ngram_metrics, comapre_unidist_cat, compute_2d_categorical_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>tcode</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>day</th>\n",
       "      <th>td</th>\n",
       "      <th>dtme</th>\n",
       "      <th>amount</th>\n",
       "      <th>raw_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>1995-03-24</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
       "      <td>1995-04-13</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>3679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>1995-04-23</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12600.0</td>\n",
       "      <td>12600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>1995-04-30</td>\n",
       "      <td>1995</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
       "      <td>1995-05-13</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>3679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056315</th>\n",
       "      <td>11382</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>1998-12-02</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>25600.0</td>\n",
       "      <td>-25600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056316</th>\n",
       "      <td>11382</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
       "      <td>1998-12-10</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21</td>\n",
       "      <td>46248.0</td>\n",
       "      <td>46248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056317</th>\n",
       "      <td>11382</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>1998-12-25</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>-6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056318</th>\n",
       "      <td>11382</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>311.3</td>\n",
       "      <td>311.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056319</th>\n",
       "      <td>11382</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>1998-12-31</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>301.1</td>\n",
       "      <td>301.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056320 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         account_id                                      tcode   datetime  \\\n",
       "0                 1                CREDIT__CREDIT IN CASH__nan 1995-03-24   \n",
       "1                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1995-04-13   \n",
       "2                 1                CREDIT__CREDIT IN CASH__nan 1995-04-23   \n",
       "3                 1             CREDIT__nan__INTEREST CREDITED 1995-04-30   \n",
       "4                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1995-05-13   \n",
       "...             ...                                        ...        ...   \n",
       "1056315       11382                DEBIT__CASH WITHDRAWAL__nan 1998-12-02   \n",
       "1056316       11382  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1998-12-10   \n",
       "1056317       11382                DEBIT__CASH WITHDRAWAL__nan 1998-12-25   \n",
       "1056318       11382             CREDIT__nan__INTEREST CREDITED 1998-12-31   \n",
       "1056319       11382             CREDIT__nan__INTEREST CREDITED 1998-12-31   \n",
       "\n",
       "         year  month  dow  day    td  dtme   amount  raw_amount  \n",
       "0        1995      3    4   24   0.0     7   1000.0      1000.0  \n",
       "1        1995      4    3   13  20.0    17   3679.0      3679.0  \n",
       "2        1995      4    6   23  10.0     7  12600.0     12600.0  \n",
       "3        1995      4    6   30   7.0     0     19.2        19.2  \n",
       "4        1995      5    5   13  13.0    18   3679.0      3679.0  \n",
       "...       ...    ...  ...  ...   ...   ...      ...         ...  \n",
       "1056315  1998      0    2    2   2.0    29  25600.0    -25600.0  \n",
       "1056316  1998      0    3   10   8.0    21  46248.0     46248.0  \n",
       "1056317  1998      0    4   25  15.0     6   6300.0     -6300.0  \n",
       "1056318  1998      0    3    0   6.0     0    311.3       311.3  \n",
       "1056319  1998      0    3    0   0.0     0    301.1       301.1  \n",
       "\n",
       "[1056320 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../DATA/tr_by_acct_w_age.csv')\n",
    "raw_data = raw_data.sort_values(by = [\"account_id\", \"date\"])\n",
    "data, LOG_AMOUNT_SCALE, TD_SCALE,ATTR_SCALE, START_DATE, _ = preprocess_data_czech(raw_data)\n",
    "real = data[['account_id','tcode', 'datetime','year', 'month', 'dow', 'day','td', 'dtme', 'amount', 'raw_amount']]\n",
    "real_cf = real[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
    "real_sorted = real.sort_values(['account_id', 'year', 'month', 'day'])\n",
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_code</th>\n",
       "      <th>account_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>days_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1993-03-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.75</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1993-03-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.12</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1993-04-05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.20</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1993-04-30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3551.89</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1993-05-11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>62.29</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>4648.60</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1998-10-16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>2223.25</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-11-04</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>61.84</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1998-11-30</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>4313.84</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1998-12-18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount                                   transaction_code  \\\n",
       "0          0.37                     CREDIT__nan__INTEREST CREDITED   \n",
       "1          2.75                          DEBIT__CASH WITHDRAWAL__    \n",
       "2         78.12  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   \n",
       "3         17.20                     CREDIT__nan__INTEREST CREDITED   \n",
       "4       3551.89                        DEBIT__CASH WITHDRAWAL__nan   \n",
       "...         ...                                                ...   \n",
       "399995    62.29                     CREDIT__nan__INTEREST CREDITED   \n",
       "399996  4648.60                        CREDIT__CREDIT IN CASH__nan   \n",
       "399997  2223.25                        DEBIT__CASH WITHDRAWAL__nan   \n",
       "399998    61.84                     CREDIT__nan__INTEREST CREDITED   \n",
       "399999  4313.84                        CREDIT__CREDIT IN CASH__nan   \n",
       "\n",
       "        account_id  year  month  day        date  days_passed  \n",
       "0                0  1993      3   28  1993-03-28            0  \n",
       "1                0  1993      3   29  1993-03-29            1  \n",
       "2                0  1993      4    5  1993-04-05            7  \n",
       "3                0  1993      4   30  1993-04-30           25  \n",
       "4                0  1993      5   11  1993-05-11           11  \n",
       "...            ...   ...    ...  ...         ...          ...  \n",
       "399995        4999  1998      9   30  1998-09-30           30  \n",
       "399996        4999  1998     10   16  1998-10-16           16  \n",
       "399997        4999  1998     11    4  1998-11-04           19  \n",
       "399998        4999  1998     11   30  1998-11-30           26  \n",
       "399999        4999  1998     12   18  1998-12-18           18  \n",
       "\n",
       "[400000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth = pd.read_csv('synth_lstm_dp1.csv')\n",
    "synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth = pd.read_csv('synth_lstm_tcode_v1.csv')\n",
    "synth.rename(columns={'days_passed': 'td', 'transaction_code': 'tcode'}, inplace=True)\n",
    "synth['type'] = synth['tcode'].str.split('__').str[0]\n",
    "synth['raw_amount'] = synth.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
    "\n",
    "synth_sorted = synth.sort_values(['account_id', 'year', 'month', 'day'])\n",
    "\n",
    "synth_cf = synth[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcode</th>\n",
       "      <th>account_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBIT__CREDIT CARD WITHDRAWAL__nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tcode  account_id\n",
       "0             DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT           0\n",
       "1                    DEBIT__CREDIT CARD WITHDRAWAL__nan           0\n",
       "2                           DEBIT__CASH WITHDRAWAL__nan           0\n",
       "3                        CREDIT__nan__INTEREST CREDITED           0\n",
       "4       DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT           0\n",
       "...                                                 ...         ...\n",
       "399995             DEBIT__REMITTANCE TO ANOTHER BANK__         4999\n",
       "399996             DEBIT__REMITTANCE TO ANOTHER BANK__         4999\n",
       "399997                      DEBIT__CASH WITHDRAWAL__nan        4999\n",
       "399998     DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD        4999\n",
       "399999     DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD        4999\n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "synth = pd.read_csv('synth_lstm_tcode.csv')\n",
    "synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>k_symbol</th>\n",
       "      <th>operation</th>\n",
       "      <th>type</th>\n",
       "      <th>account_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>td</th>\n",
       "      <th>tcode</th>\n",
       "      <th>raw_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.38</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CREDIT CARD WITHDRAWAL</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>1996-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>DEBIT__CREDIT CARD WITHDRAWAL__HOUSEHOLD</td>\n",
       "      <td>-7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.91</td>\n",
       "      <td>_nan</td>\n",
       "      <td>CASH WITHDRAWAL</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1996-10-02</td>\n",
       "      <td>3</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL___nan</td>\n",
       "      <td>-92.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.13</td>\n",
       "      <td>PAYMENT ON STATEMENT</td>\n",
       "      <td>CASH WITHDRAWAL</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>1996-10-31</td>\n",
       "      <td>29</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1543.77</td>\n",
       "      <td>_nan</td>\n",
       "      <td>CREDIT CARD WITHDRAWAL</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1996-11-07</td>\n",
       "      <td>7</td>\n",
       "      <td>DEBIT__CREDIT CARD WITHDRAWAL___nan</td>\n",
       "      <td>-1543.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213.19</td>\n",
       "      <td>INTEREST CREDITED</td>\n",
       "      <td>_nan</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1996-11-09</td>\n",
       "      <td>2</td>\n",
       "      <td>CREDIT___nan__INTEREST CREDITED</td>\n",
       "      <td>213.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>861.83</td>\n",
       "      <td>_nan</td>\n",
       "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>4999</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1995-06-14</td>\n",
       "      <td>0</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK___nan</td>\n",
       "      <td>861.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>290.86</td>\n",
       "      <td>_nan</td>\n",
       "      <td>CASH WITHDRAWAL</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>4999</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1995-06-17</td>\n",
       "      <td>3</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL___nan</td>\n",
       "      <td>-290.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>279.76</td>\n",
       "      <td>_nan</td>\n",
       "      <td>REMITTANCE TO ANOTHER BANK</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>4999</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1995-06-18</td>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT__REMITTANCE TO ANOTHER BANK___nan</td>\n",
       "      <td>-279.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>1062.36</td>\n",
       "      <td>_nan</td>\n",
       "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>4999</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1995-06-22</td>\n",
       "      <td>4</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK___nan</td>\n",
       "      <td>1062.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>1311.45</td>\n",
       "      <td>_nan</td>\n",
       "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>4999</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1995-06-25</td>\n",
       "      <td>3</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK___nan</td>\n",
       "      <td>1311.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount              k_symbol                     operation    type  \\\n",
       "0          7.38             HOUSEHOLD        CREDIT CARD WITHDRAWAL   DEBIT   \n",
       "1         92.91                  _nan               CASH WITHDRAWAL   DEBIT   \n",
       "2          0.13  PAYMENT ON STATEMENT               CASH WITHDRAWAL   DEBIT   \n",
       "3       1543.77                  _nan        CREDIT CARD WITHDRAWAL   DEBIT   \n",
       "4        213.19     INTEREST CREDITED                          _nan  CREDIT   \n",
       "...         ...                   ...                           ...     ...   \n",
       "399995   861.83                  _nan  COLLECTION FROM ANOTHER BANK  CREDIT   \n",
       "399996   290.86                  _nan               CASH WITHDRAWAL   DEBIT   \n",
       "399997   279.76                  _nan    REMITTANCE TO ANOTHER BANK   DEBIT   \n",
       "399998  1062.36                  _nan  COLLECTION FROM ANOTHER BANK  CREDIT   \n",
       "399999  1311.45                  _nan  COLLECTION FROM ANOTHER BANK  CREDIT   \n",
       "\n",
       "        account_id  year  month  day        date  td  \\\n",
       "0                0  1996      9   29  1996-09-29   0   \n",
       "1                0  1996     10    2  1996-10-02   3   \n",
       "2                0  1996     10   31  1996-10-31  29   \n",
       "3                0  1996     11    7  1996-11-07   7   \n",
       "4                0  1996     11    9  1996-11-09   2   \n",
       "...            ...   ...    ...  ...         ...  ..   \n",
       "399995        4999  1995      6   14  1995-06-14   0   \n",
       "399996        4999  1995      6   17  1995-06-17   3   \n",
       "399997        4999  1995      6   18  1995-06-18   1   \n",
       "399998        4999  1995      6   22  1995-06-22   4   \n",
       "399999        4999  1995      6   25  1995-06-25   3   \n",
       "\n",
       "                                               tcode  raw_amount  \n",
       "0           DEBIT__CREDIT CARD WITHDRAWAL__HOUSEHOLD       -7.38  \n",
       "1                       DEBIT__CASH WITHDRAWAL___nan      -92.91  \n",
       "2       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT       -0.13  \n",
       "3                DEBIT__CREDIT CARD WITHDRAWAL___nan    -1543.77  \n",
       "4                    CREDIT___nan__INTEREST CREDITED      213.19  \n",
       "...                                              ...         ...  \n",
       "399995    CREDIT__COLLECTION FROM ANOTHER BANK___nan      861.83  \n",
       "399996                  DEBIT__CASH WITHDRAWAL___nan     -290.86  \n",
       "399997       DEBIT__REMITTANCE TO ANOTHER BANK___nan     -279.76  \n",
       "399998    CREDIT__COLLECTION FROM ANOTHER BANK___nan     1062.36  \n",
       "399999    CREDIT__COLLECTION FROM ANOTHER BANK___nan     1311.45  \n",
       "\n",
       "[400000 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth = pd.read_csv('synth_lstm_v3.csv')\n",
    "cat_code_fields = ['type', 'operation', 'k_symbol']\n",
    "TCODE_SEP = \"__\"\n",
    "# create tcode by concating fields in \"cat_code_fields\"\n",
    "tcode = synth[cat_code_fields[0]].astype(str)\n",
    "for ccf in cat_code_fields[1:]:\n",
    "    tcode += TCODE_SEP + synth[ccf].astype(str)\n",
    "\n",
    "synth[\"tcode\"] = tcode\n",
    "\n",
    "synth.rename(columns={'days_passed': 'td'}, inplace=True)\n",
    "synth['raw_amount'] = synth.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
    "\n",
    "synth_sorted = synth.sort_values(['account_id', 'year', 'month', 'day'])\n",
    "\n",
    "synth_cf = synth[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
    "synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_code</th>\n",
       "      <th>account_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>days_passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1993-03-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.75</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>1993-03-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.12</td>\n",
       "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1993-04-05</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.20</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1993-04-30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3551.89</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>0</td>\n",
       "      <td>1993</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1993-05-11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>62.29</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1998-09-30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>4648.60</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1998-10-16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>2223.25</td>\n",
       "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1998-11-04</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>61.84</td>\n",
       "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1998-11-30</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>4313.84</td>\n",
       "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
       "      <td>4999</td>\n",
       "      <td>1998</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1998-12-18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount                                   transaction_code  \\\n",
       "0          0.37                     CREDIT__nan__INTEREST CREDITED   \n",
       "1          2.75                          DEBIT__CASH WITHDRAWAL__    \n",
       "2         78.12  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   \n",
       "3         17.20                     CREDIT__nan__INTEREST CREDITED   \n",
       "4       3551.89                        DEBIT__CASH WITHDRAWAL__nan   \n",
       "...         ...                                                ...   \n",
       "399995    62.29                     CREDIT__nan__INTEREST CREDITED   \n",
       "399996  4648.60                        CREDIT__CREDIT IN CASH__nan   \n",
       "399997  2223.25                        DEBIT__CASH WITHDRAWAL__nan   \n",
       "399998    61.84                     CREDIT__nan__INTEREST CREDITED   \n",
       "399999  4313.84                        CREDIT__CREDIT IN CASH__nan   \n",
       "\n",
       "        account_id  year  month  day        date  days_passed  \n",
       "0                0  1993      3   28  1993-03-28            0  \n",
       "1                0  1993      3   29  1993-03-29            1  \n",
       "2                0  1993      4    5  1993-04-05            7  \n",
       "3                0  1993      4   30  1993-04-30           25  \n",
       "4                0  1993      5   11  1993-05-11           11  \n",
       "...            ...   ...    ...  ...         ...          ...  \n",
       "399995        4999  1998      9   30  1998-09-30           30  \n",
       "399996        4999  1998     10   16  1998-10-16           16  \n",
       "399997        4999  1998     11    4  1998-11-04           19  \n",
       "399998        4999  1998     11   30  1998-11-30           26  \n",
       "399999        4999  1998     12   18  1998-12-18           18  \n",
       "\n",
       "[400000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth = pd.read_csv('synth_lstm_dp1.csv')\n",
    "synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "czech_date_parser = lambda x: datetime.strptime(str(x), \"%Y-%m-%d\")\n",
    "synth[\"datetime\"] = synth[\"date\"].apply(czech_date_parser)\n",
    "synth[\"month\"] = synth[\"datetime\"].dt.month \n",
    "synth[\"day\"] = synth[\"datetime\"].dt.day \n",
    "synth[\"dow\"] =  synth[\"datetime\"].dt.dayofweek \n",
    "synth[\"year\"] = synth[\"datetime\"].dt.year\n",
    "synth['tcode'] = synth['transaction_code']\n",
    "synth.rename(columns={'days_passed': 'td'}, inplace=True)\n",
    "synth['type'] = synth['tcode'].str.split('__').str[0]\n",
    "synth['raw_amount'] = synth.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
    "\n",
    "synth_sorted = synth.sort_values(['account_id', 'year', 'month', 'day'])\n",
    "\n",
    "synth_cf = synth[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth[synth['account_id'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': {'wasser': 4174.573380036866,\n",
       "  'ks': 0.24605198424719776,\n",
       "  'energy_d': 34.9193550921508},\n",
       " 'td': {'wasser': 10.252238490608907,\n",
       "  'ks': 0.25543474250227205,\n",
       "  'energy_d': 1.8358876046889725},\n",
       " 'CF': {'wasser': 4226.028779972578,\n",
       "  'ks': 0.15893154299225914,\n",
       "  'energy_d': 24.163848319263757}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONT_FIELDS = [\"amount\", \"td\"]\n",
    "\n",
    "CF_FIELD = 'raw_amount'\n",
    "\n",
    "#compare univariate distribution of continuous columns\n",
    "comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real, synth, real_cf, synth_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jsd': 0.24065076970017257,\n",
       " 'entr_r': 5.351895164576639,\n",
       " 'entr_g': 5.4837167582921555,\n",
       " 'NED': -0.13182159371551627,\n",
       " 'l1': 1.1322630832101863,\n",
       " 'l2': 0.11318215558365517,\n",
       " 'jac': 0.5880572372041827,\n",
       " 'count_r': 1548,\n",
       " 'coverage_r': 0.3779296875,\n",
       " 'count_g': 3583,\n",
       " 'coverage_g': 0.874755859375,\n",
       " 'count_max': 4096,\n",
       " 'field': 'tcode',\n",
       " 'n': 3,\n",
       " 'pseudo_counts': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSD between the distributions of tcode 3-grams\n",
    "synth_sorted = synth\n",
    "combo_df, result = compute_ngram_metrics(real_sorted, synth_sorted, 'tcode', 3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcode': 0.0353668998874559, 'day': 0.14706534597241305}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSD result comparing the univariate distributions of the tcode (Tcode), and DOM\n",
    "#CAT_FIELDS = ['tcode', 'day', 'month']\n",
    "CAT_FIELDS = ['tcode', 'day']\n",
    "result_jst_cat = {}\n",
    "for field in CAT_FIELDS:\n",
    "    result_jst_cat[field] = comapre_unidist_cat(real, synth, field)\n",
    "result_jst_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jsd': 0.2127952776525589,\n",
       " 'entr_r': 4.3143515019943885,\n",
       " 'entr_g': 4.663408977516541,\n",
       " 'l1': 0.883125640714935,\n",
       " 'l2': 0.19175228938017574,\n",
       " 'jac': 0.5396825396825397,\n",
       " 'count_r': 240.0,\n",
       " 'coverage_r': 0.46875,\n",
       " 'count_g': 496.0,\n",
       " 'coverage_g': 0.96875,\n",
       " 'count_max': 512}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joint distribution of two categorical columns(tcode, DOM)\n",
    "field1 = 'tcode'\n",
    "field2 = 'day'\n",
    "compute_2d_categorical_metrics(real, synth, field1, field2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
